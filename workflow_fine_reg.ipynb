{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools as ft\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "import zarr_io\n",
    "import fine_registration\n",
    "\n",
    "from sofima import stitch_elastic, flow_utils, mesh  # Other stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('coarse_results.npz')\n",
    "cx = data['cx']\n",
    "cy = data['cy']\n",
    "coarse_mesh = data['mesh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1684534367.550418 2125426 gcs_resource.cc:102] Using default AdmissionQueue with limit 32\n",
      "I0000 00:00:1684534367.552101 2125695 google_auth_provider.cc:179] Running on GCE, using service account 895865026362-compute@developer.gserviceaccount.com\n"
     ]
    }
   ],
   "source": [
    "bucket = 'sofima-test-bucket'\n",
    "path_0 = f'preprocessed_0.zarr'\n",
    "path_1 = f'preprocessed_1.zarr'\n",
    "tile_0 = zarr_io.open_zarr(bucket, path_0)\n",
    "tile_1 = zarr_io.open_zarr(bucket, path_1)\n",
    "\n",
    "# Existing data structures:\n",
    "tile_layout = np.array([[0], \n",
    "                        [1]])\n",
    "idx_to_coord = {0:(0, 0), 1:(1, 0)}\n",
    "\n",
    "# Must load in 4 dimensions: 1zyx shape\n",
    "# tile_volumes = [tile_0[0,:,:,:,:].resize(exclusive_max=(1, 3544, 576, 576)).result(), \n",
    "#                 tile_1[0,:,:,:,:]]\n",
    "\n",
    "tile_volumes = [tile_0[0,:,:,:,:], tile_1[0,:,:,:,:]]\n",
    "\n",
    "# Replacing 'tile_map' with SyncAdapter objects and adopting reverse basis\n",
    "tile_map = {(0, 0): fine_registration.SyncAdapter(tile_volumes[0], 0), \n",
    "            (0, 1): fine_registration.SyncAdapter(tile_volumes[1], 1)}\n",
    "# Different basis\n",
    "idx_to_coord = {0:(0, 0), 1:(0, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(slice(None, None, None), slice(0, 3544, None), slice(280, 576, None), slice(0, 576, None))\n",
      "(slice(None, None, None), slice(0, 3544, None), slice(0, 296, None), slice(0, 576, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 22:12:56.644616: W external/xla/xla/service/gpu/gpu_conv_algorithm_picker.cc:850] None of the algorithms provided by cuDNN heuristics worked; trying fallback algorithms.\n",
      "2023-05-19 22:12:56.644654: W external/xla/xla/service/gpu/gpu_conv_algorithm_picker.cc:853] Conv: (f32[16,5,159,159,159]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[16,1,159,159,159]{4,3,2,1,0}, f32[5,1,5,1,1]{4,3,2,1,0}), window={size=5x1x1 pad=2_2x0_0x0_0}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convForward\", backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n%cudnn-conv.3 = (f32[16,5,159,159,159]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[16,1,159,159,159]{4,3,2,1,0} %bitcast.250, f32[5,1,5,1,1]{4,3,2,1,0} %bitcast.258), window={size=5x1x1 pad=2_2x0_0x0_0}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convForward\", metadata={op_name=\"jit(batched_xcorr_peaks)/jit(main)/conv_general_dilated[window_strides=(1, 1, 1) padding=((2, 2), (0, 0), (0, 0)) lhs_dilation=(1, 1, 1) rhs_dilation=(1, 1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 1, 2, 3, 4), rhs_spec=(0, 1, 2, 3, 4), out_spec=(0, 1, 2, 3, 4)) feature_group_count=1 batch_group_count=1 precision=None preferred_element_type=None]\" source_file=\"/home/jonathan.wong/sofima-testing/fine_registration.py\" source_line=149}, backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\n\nOriginal error: INTERNAL: All algorithms tried for %cudnn-conv.3 = (f32[16,5,159,159,159]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[16,1,159,159,159]{4,3,2,1,0} %bitcast.250, f32[5,1,5,1,1]{4,3,2,1,0} %bitcast.258), window={size=5x1x1 pad=2_2x0_0x0_0}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convForward\", metadata={op_name=\"jit(batched_xcorr_peaks)/jit(main)/conv_general_dilated[window_strides=(1, 1, 1) padding=((2, 2), (0, 0), (0, 0)) lhs_dilation=(1, 1, 1) rhs_dilation=(1, 1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 1, 2, 3, 4), rhs_spec=(0, 1, 2, 3, 4), out_spec=(0, 1, 2, 3, 4)) feature_group_count=1 batch_group_count=1 precision=None preferred_element_type=None]\" source_file=\"/home/jonathan.wong/sofima-testing/fine_registration.py\" source_line=149}, backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\" failed. Falling back to default algorithm.  Per-algorithm errors:\n  Profiling failure on cuDNN engine eng0{}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng28{k2=4,k3=0}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng28{k2=3,k3=0}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng48{k2=15,k6=0,k13=1,k14=0,k22=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng48{k2=2,k6=0,k13=1,k14=0,k22=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng28{k2=0,k3=0}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng36{k2=4,k13=0,k14=2,k18=0,k23=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng36{k2=0,k13=2,k14=3,k18=0,k23=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng36{k2=1,k13=0,k14=4,k18=0,k23=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng38{k2=8,k13=1,k14=4,k18=0,k22=0,k23=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng36{k2=5,k13=1,k14=3,k18=1,k23=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng36{k2=5,k13=1,k14=3,k18=0,k23=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng28{k2=1,k3=0}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng36{k2=7,k13=0,k14=4,k18=0,k23=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng38{k2=0,k13=2,k14=3,k18=1,k22=0,k23=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng28{}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng0{}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m tile_size_xyz \u001b[39m=\u001b[39m (\u001b[39m576\u001b[39m, \u001b[39m576\u001b[39m, \u001b[39m3544\u001b[39m)  \u001b[39m# Yet it expects the tiles as 1zyx...\u001b[39;00m\n\u001b[1;32m      4\u001b[0m flow_x, offsets_x \u001b[39m=\u001b[39m fine_registration\u001b[39m.\u001b[39mcompute_flow_map3d(tile_map,\n\u001b[1;32m      5\u001b[0m                                                         tile_size_xyz, cx, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m      6\u001b[0m                                                         stride\u001b[39m=\u001b[39mstride,\n\u001b[1;32m      7\u001b[0m                                                         patch_size\u001b[39m=\u001b[39m(\u001b[39m80\u001b[39m, \u001b[39m80\u001b[39m, \u001b[39m80\u001b[39m))\n\u001b[0;32m----> 9\u001b[0m flow_y, offsets_y \u001b[39m=\u001b[39m fine_registration\u001b[39m.\u001b[39;49mcompute_flow_map3d(tile_map,\n\u001b[1;32m     10\u001b[0m                                                         tile_size_xyz, cy, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m                                                         stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m     12\u001b[0m                                                         patch_size\u001b[39m=\u001b[39;49m(\u001b[39m80\u001b[39;49m, \u001b[39m80\u001b[39;49m, \u001b[39m80\u001b[39;49m))\n\u001b[1;32m     14\u001b[0m np\u001b[39m.\u001b[39msavez_compressed(\u001b[39m'\u001b[39m\u001b[39mflow_results.npz\u001b[39m\u001b[39m'\u001b[39m, flow_x\u001b[39m=\u001b[39mflow_x, flow_y\u001b[39m=\u001b[39mflow_y, offsets_x\u001b[39m=\u001b[39moffsets_x, offsets_y\u001b[39m=\u001b[39moffsets_y)\n",
      "File \u001b[0;32m~/sofima-testing/fine_registration.py:149\u001b[0m, in \u001b[0;36mcompute_flow_map3d\u001b[0;34m(tile_map, tile_shape, offset_map, axis, patch_size, stride, batch_size)\u001b[0m\n\u001b[1;32m    145\u001b[0m     post \u001b[39m=\u001b[39m tile_post[isec_nbor\u001b[39m.\u001b[39mto_slice4d()]\u001b[39m.\u001b[39msqueeze(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    147\u001b[0m     \u001b[39massert\u001b[39;00m pre\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m post\u001b[39m.\u001b[39mshape\n\u001b[0;32m--> 149\u001b[0m     f \u001b[39m=\u001b[39m mfc\u001b[39m.\u001b[39;49mflow_field(\n\u001b[1;32m    150\u001b[0m         pre, post, patch_size\u001b[39m=\u001b[39;49mpatch_size, step\u001b[39m=\u001b[39;49mstride, batch_size\u001b[39m=\u001b[39;49mbatch_size\n\u001b[1;32m    151\u001b[0m     )\n\u001b[1;32m    152\u001b[0m     ret[(x, y)] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mpad(\n\u001b[1;32m    153\u001b[0m         f, [[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m]] \u001b[39m+\u001b[39m [[p, p \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m pad_zyx], constant_values\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mnan\n\u001b[1;32m    154\u001b[0m     )\n\u001b[1;32m    156\u001b[0m \u001b[39mreturn\u001b[39;00m ret, offsets\n",
      "File \u001b[0;32m/opt/conda/envs/py311/lib/python3.11/site-packages/sofima/flow_field.py:508\u001b[0m, in \u001b[0;36mJAXMaskedXCorrWithStatsCalculator.flow_field\u001b[0;34m(self, pre_image, post_image, patch_size, step, pre_mask, post_mask, mask_only_for_patch_selection, selection_mask, max_masked, batch_size, post_patch_size)\u001b[0m\n\u001b[1;32m    505\u001b[0m starts \u001b[39m=\u001b[39m pos \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39marray(step)\u001b[39m.\u001b[39mreshape((\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m    506\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39m.. estimating \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m patches.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlen\u001b[39m(pos))\n\u001b[1;32m    507\u001b[0m peaks \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\n\u001b[0;32m--> 508\u001b[0m     batched_xcorr_peaks(\n\u001b[1;32m    509\u001b[0m         pre_image,\n\u001b[1;32m    510\u001b[0m         post_image,\n\u001b[1;32m    511\u001b[0m         pre_mask,\n\u001b[1;32m    512\u001b[0m         post_mask,\n\u001b[1;32m    513\u001b[0m         patch_size,\n\u001b[1;32m    514\u001b[0m         jnp\u001b[39m.\u001b[39;49marray(starts),\n\u001b[1;32m    515\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mean,\n\u001b[1;32m    516\u001b[0m         post_patch_size\u001b[39m=\u001b[39;49mpost_patch_size,\n\u001b[1;32m    517\u001b[0m         min_distance\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_min_distance,\n\u001b[1;32m    518\u001b[0m         peak_radius\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_peak_radius))\n\u001b[1;32m    519\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39m.. done.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    520\u001b[0m \u001b[39mfor\u001b[39;00m i, coord \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(pos):\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/py311/lib/python3.11/site-packages/jax/_src/dispatch.py:463\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, module, options, host_callbacks)\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39mcompile(built_c, compile_options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m    459\u001b[0m                          host_callbacks\u001b[39m=\u001b[39mhost_callbacks)\n\u001b[1;32m    460\u001b[0m \u001b[39m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \u001b[39m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \u001b[39m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m--> 463\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mcompile(built_c, compile_options\u001b[39m=\u001b[39;49moptions)\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n%cudnn-conv.3 = (f32[16,5,159,159,159]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[16,1,159,159,159]{4,3,2,1,0} %bitcast.250, f32[5,1,5,1,1]{4,3,2,1,0} %bitcast.258), window={size=5x1x1 pad=2_2x0_0x0_0}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convForward\", metadata={op_name=\"jit(batched_xcorr_peaks)/jit(main)/conv_general_dilated[window_strides=(1, 1, 1) padding=((2, 2), (0, 0), (0, 0)) lhs_dilation=(1, 1, 1) rhs_dilation=(1, 1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 1, 2, 3, 4), rhs_spec=(0, 1, 2, 3, 4), out_spec=(0, 1, 2, 3, 4)) feature_group_count=1 batch_group_count=1 precision=None preferred_element_type=None]\" source_file=\"/home/jonathan.wong/sofima-testing/fine_registration.py\" source_line=149}, backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\n\nOriginal error: INTERNAL: All algorithms tried for %cudnn-conv.3 = (f32[16,5,159,159,159]{4,3,2,1,0}, u8[0]{0}) custom-call(f32[16,1,159,159,159]{4,3,2,1,0} %bitcast.250, f32[5,1,5,1,1]{4,3,2,1,0} %bitcast.258), window={size=5x1x1 pad=2_2x0_0x0_0}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convForward\", metadata={op_name=\"jit(batched_xcorr_peaks)/jit(main)/conv_general_dilated[window_strides=(1, 1, 1) padding=((2, 2), (0, 0), (0, 0)) lhs_dilation=(1, 1, 1) rhs_dilation=(1, 1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 1, 2, 3, 4), rhs_spec=(0, 1, 2, 3, 4), out_spec=(0, 1, 2, 3, 4)) feature_group_count=1 batch_group_count=1 precision=None preferred_element_type=None]\" source_file=\"/home/jonathan.wong/sofima-testing/fine_registration.py\" source_line=149}, backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\" failed. Falling back to default algorithm.  Per-algorithm errors:\n  Profiling failure on cuDNN engine eng0{}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng28{k2=4,k3=0}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng28{k2=3,k3=0}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng48{k2=15,k6=0,k13=1,k14=0,k22=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng48{k2=2,k6=0,k13=1,k14=0,k22=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng28{k2=0,k3=0}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng36{k2=4,k13=0,k14=2,k18=0,k23=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng36{k2=0,k13=2,k14=3,k18=0,k23=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng36{k2=1,k13=0,k14=4,k18=0,k23=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng38{k2=8,k13=1,k14=4,k18=0,k22=0,k23=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng36{k2=5,k13=1,k14=3,k18=1,k23=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng36{k2=5,k13=1,k14=3,k18=0,k23=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng28{k2=1,k3=0}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng36{k2=7,k13=0,k14=4,k18=0,k23=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng38{k2=0,k13=2,k14=3,k18=1,k22=0,k23=0}: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng28{}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n  Profiling failure on cuDNN engine eng0{}: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin external/xla/xla/stream_executor/cuda/cuda_dnn.cc(4686): 'status'\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning."
     ]
    }
   ],
   "source": [
    "# Fine Registration, compute patch flows\n",
    "stride = 20, 20, 20\n",
    "tile_size_xyz = (576, 576, 3544)  # Yet it expects the tiles as 1zyx...\n",
    "flow_x, offsets_x = fine_registration.compute_flow_map3d(tile_map,\n",
    "                                                        tile_size_xyz, cx, axis=0,\n",
    "                                                        stride=stride,\n",
    "                                                        patch_size=(80, 80, 80))\n",
    "\n",
    "flow_y, offsets_y = fine_registration.compute_flow_map3d(tile_map,\n",
    "                                                        tile_size_xyz, cy, axis=1,\n",
    "                                                        stride=stride,\n",
    "                                                        patch_size=(80, 80, 80))\n",
    "\n",
    "np.savez_compressed('flow_results.npz', flow_x=flow_x, flow_y=flow_y, offsets_x=offsets_x, offsets_y=offsets_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine Registration, filter patch flows\n",
    "kwargs = {\"min_peak_ratio\": 1.4, \"min_peak_sharpness\": 1.4, \"max_deviation\": 5, \"max_magnitude\": 0, \"dim\": 3}\n",
    "fine_x = {k: flow_utils.clean_flow(v, **kwargs) for k, v in flow_x.items()}\n",
    "fine_y = {k: flow_utils.clean_flow(v, **kwargs) for k, v in flow_y.items()}\n",
    "\n",
    "kwargs = {\"min_patch_size\": 10, \"max_gradient\": -1, \"max_deviation\": -1}\n",
    "fine_x = {k: flow_utils.reconcile_flows([v], **kwargs) for k, v in fine_x.items()}\n",
    "fine_y = {k: flow_utils.reconcile_flows([v], **kwargs) for k, v in fine_y.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine Registration, update mesh (convert coarse tile mesh into fine patch mesh)\n",
    "data_x = (cx[:, 0, ...], fine_x, offsets_x)\n",
    "data_y = (cy[:, 0, ...], fine_y, offsets_y)\n",
    "\n",
    "fx, fy, init_x, nbors, key_to_idx = stitch_elastic.aggregate_arrays(\n",
    "    data_x, data_y, list(tile_map.keys()),\n",
    "    coarse_mesh[:, 0, ...], stride=stride, tile_shape=tile_size_xyz[::-1])\n",
    "\n",
    "@jax.jit\n",
    "def prev_fn(x):\n",
    "  target_fn = ft.partial(stitch_elastic.compute_target_mesh, x=x, fx=fx, fy=fy, stride=stride)\n",
    "  x = jax.vmap(target_fn)(nbors)\n",
    "  return jnp.transpose(x, [1, 0, 2, 3, 4])\n",
    "\n",
    "config = mesh.IntegrationConfig(dt=0.001, gamma=0., k0=0.01, k=0.1, stride=stride,\n",
    "                                num_iters=1000, max_iters=20000, stop_v_max=0.001,\n",
    "                                dt_max=100, prefer_orig_order=False,\n",
    "                                start_cap=0.1, final_cap=10., remove_drift=True)\n",
    "\n",
    "x, ekin, t = mesh.relax_mesh(init_x, None, config, prev_fn=prev_fn, mesh_force=mesh.elastic_mesh_3d)\n",
    "\n",
    "np.savez_compressed('solved_mesh_st20.npz', x=x, key_to_idx=key_to_idx)  # This 'x' is the solved patch mesh(es)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
